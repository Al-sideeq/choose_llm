{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d90d45-2d19-49c7-b853-6809dc417ea7",
   "metadata": {},
   "source": [
    "## Dataset Curator for Project 3\n",
    "### Example code for simple equity trading decisions\n",
    "\n",
    "There are 3 sample python files generated (via multiple queries) by GPT-4o, Claude 3 Opus and Gemini 1.5 Pro.\n",
    "This notebook creates training data from these files, then converts to the HuggingFace format and uploads to the hub.\n",
    "\n",
    "It goes without saying: this trading code was generated by LLMs, is over-simplified and untrusted - do not make actual trading decisions based on this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf3aa2-f407-4b95-8b9e-c3c586f67835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datasets import Dataset\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import transformers\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375302b6-b6a7-46ea-a74c-c2400dbd8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "from datasets import load_dataset, Dataset\n",
    "load_dotenv()\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-hf-token-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c9fff-9eff-42fd-971b-403c99d9b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATASET_NAME = \"trade_code_dataset\"\n",
    "BASE_MODEL = \"bigcode/starcoder2-3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b07ba-5396-4c34-a696-01c8bc3597a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to convert the text contents of a file into a list of methods\n",
    "\n",
    "def extract_method_bodies(text):\n",
    "    chunks = text.split('def trade')[1:]\n",
    "    results = []\n",
    "    for chunk in chunks:\n",
    "        lines = chunk.split('\\n')[1:]\n",
    "        body = '\\n'.join(line for line in lines if line!='\\n')\n",
    "        results.append(body)\n",
    "    return results          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953422d0-2e75-4d01-862e-6383df54d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all .py files and convert into training data\n",
    "\n",
    "bodies = []\n",
    "for filename in glob.glob(\"*.py\"):\n",
    "    with open(filename, 'r') as file:\n",
    "        content = file.read()\n",
    "        extracted = extract_method_bodies(content)\n",
    "        bodies += extracted\n",
    "\n",
    "print(f\"Extracted {len(bodies)} trade method bodies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836480e9-ba23-4aa3-a7e2-2666884e9a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at one\n",
    "\n",
    "print(random.choice(bodies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b10e7e-a562-4968-af3f-254a9b424ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize the lines of code in each \n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "lengths = [len(body.split('\\n')) for body in bodies]\n",
    "ax.set_xlabel('Lines of code')\n",
    "ax.set_ylabel('Count of training samples');\n",
    "_ = ax.hist(lengths, rwidth=0.7, color=\"green\", bins=range(0, max(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b37f62-679e-4c3d-9e5b-5878a82696e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the prompt to the start of every training example\n",
    "\n",
    "prompt = \"\"\"\n",
    "# tickers is a list of stock tickers\n",
    "import tickers\n",
    "\n",
    "# prices is a dict; the key is a ticker and the value is a list of historic prices, today first\n",
    "import prices\n",
    "\n",
    "# Trade represents a decision to buy or sell a quantity of a ticker\n",
    "import Trade\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def trade():\n",
    "\"\"\"\n",
    "\n",
    "data = [prompt + body for body in bodies]\n",
    "print(random.choice(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fdb82f-3864-4023-8263-547d17571a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of tokens in our dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
    "tokenized_data = [tokenizer.encode(each) for each in data]\n",
    "token_counts = [len(tokens) for tokens in tokenized_data]\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_xlabel('Number of tokens')\n",
    "ax.set_ylabel('Count of training samples');\n",
    "_ = ax.hist(token_counts, rwidth=0.7, color=\"purple\", bins=range(0, max(token_counts), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0d55c-5602-4518-b811-fa385c0959a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF = 320\n",
    "truncated = len([tokens for tokens in tokenized_data if len(tokens) > CUTOFF])\n",
    "percentage = truncated/len(tokenized_data)*100\n",
    "print(f\"With cutoff at {CUTOFF}, we truncate {truncated} datapoints which is {percentage:.1f}% of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bb067-2bd3-498b-9fc8-5e8186afbe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26713fb9-765f-4524-b9db-447e97686d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't make a Training / Test split - if we had more training data, we would!\n",
    "\n",
    "dataset = Dataset.from_dict({'text':data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabba27-ef47-46a8-a26b-4d650ae3b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b595cd-2df7-4be4-aec1-0667b17d36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(DATASET_NAME, private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4691a025-9800-4e97-a20f-a65f102401f1",
   "metadata": {},
   "source": [
    "## And now to head over to a Google Colab for fine-tuning in the cloud\n",
    "\n",
    "Follow this link for the Colab: https://colab.research.google.com/drive/19E9hoAzWKvn9c9SHqM4Xan_Ph4wNewHS?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a6c3e0-a2e6-4115-a01a-45e79dfdb730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
